{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'results-nofeat-msg.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: ['1000']\n",
      "Test Batch Size: 1000\n",
      "0.7178008348545071\n",
      "0.5727617585511668\n",
      "0.6321330006467324\n",
      "0.7272813080543505\n",
      "0.8362875087229588\n",
      "0.7809346426239723\n",
      "0.7965299124038308\n",
      "0.6621209650102247\n",
      "0.6084798879681307\n",
      "0.7820409864059952\n",
      "0.862787247143392\n",
      "0.7617760341976143\n",
      "0.8285470518193494\n",
      "0.776455380226442\n",
      "0.7158126492268099\n",
      "0.6067923273397412\n",
      "0.5831149927219796\n",
      "0.8336770593230619\n",
      "0.7579028290911619\n",
      "0.6775329056520297\n",
      "0.6098022543337542\n",
      "0.6610468304819487\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"../reproduce_gaze\\\\nofeat-msg\\\\batch_1000\\\\log\\\\log-test-link-gaze-S12-0214194115\"\n",
    "\n",
    "# Read the text from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Regular expression patterns to extract data\n",
    "batch_size_pattern = r\"batch_size=(\\d+)\"\n",
    "test_batch_size_pattern = r\"test_batch_size: (\\d+)\"\n",
    "session_pattern = r\"Session: (.+?)\\n\"\n",
    "f1_score_pattern = r\"all f1: ([0-9.]+)\"\n",
    "\n",
    "\n",
    "# Extract data using regex\n",
    "batch_size = re.findall(batch_size_pattern, text)\n",
    "test_batch_size = re.findall(test_batch_size_pattern, text)\n",
    "sessions = re.findall(session_pattern, text)\n",
    "f1_scores = re.findall(f1_score_pattern, text)\n",
    "\n",
    "# Calculating average F1 score\n",
    "average_f1 = sum(map(float, f1_scores)) / len(f1_scores) if f1_scores else None\n",
    "\n",
    "# Prepare data for writing to file\n",
    "lines_to_write = [\n",
    "    f\"Batch Size: {batch_size}\",\n",
    "    f\"Test Batch Size: {test_batch_size[0]}\",\n",
    "    f\"{average_f1}\"\n",
    "    # f\"Average F1 Score: {average_f1}\"\n",
    "]\n",
    "lines_to_write.extend([f\"{score}\" for i, score in enumerate(f1_scores)])\n",
    "# lines_to_write.extend([f\"F1 Score Session {i+1}: {score}\" for i, score in enumerate(f1_scores)])\n",
    "\n",
    "# Write to a new file\n",
    "with open(output_file_path, 'a') as file:\n",
    "    for line in lines_to_write:\n",
    "        file.write(line + '\\n')\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "# Displaying what was written to the file\n",
    "print('\\n'.join(lines_to_write))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>test_batch_size</th>\n",
       "      <th>f1_score_session_1</th>\n",
       "      <th>f1_score_session_2</th>\n",
       "      <th>f1_score_session_3</th>\n",
       "      <th>f1_score_session_4</th>\n",
       "      <th>f1_score_session_5</th>\n",
       "      <th>f1_score_session_6</th>\n",
       "      <th>f1_score_session_7</th>\n",
       "      <th>f1_score_session_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f1_score_session_13</th>\n",
       "      <th>f1_score_session_14</th>\n",
       "      <th>f1_score_session_15</th>\n",
       "      <th>f1_score_session_16</th>\n",
       "      <th>f1_score_session_17</th>\n",
       "      <th>f1_score_session_18</th>\n",
       "      <th>f1_score_session_19</th>\n",
       "      <th>f1_score_session_20</th>\n",
       "      <th>f1_score_session_21</th>\n",
       "      <th>average_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.75535</td>\n",
       "      <td>0.790916</td>\n",
       "      <td>0.845031</td>\n",
       "      <td>0.895671</td>\n",
       "      <td>0.879439</td>\n",
       "      <td>0.875394</td>\n",
       "      <td>0.809528</td>\n",
       "      <td>0.769708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903456</td>\n",
       "      <td>0.854116</td>\n",
       "      <td>0.820349</td>\n",
       "      <td>0.83538</td>\n",
       "      <td>0.933664</td>\n",
       "      <td>0.909538</td>\n",
       "      <td>0.836646</td>\n",
       "      <td>0.802508</td>\n",
       "      <td>0.868471</td>\n",
       "      <td>0.860156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  batch_size test_batch_size  f1_score_session_1  f1_score_session_2  \\\n",
       "0        100             100             0.75535            0.790916   \n",
       "\n",
       "   f1_score_session_3  f1_score_session_4  f1_score_session_5  \\\n",
       "0            0.845031            0.895671            0.879439   \n",
       "\n",
       "   f1_score_session_6  f1_score_session_7  f1_score_session_8  ...  \\\n",
       "0            0.875394            0.809528            0.769708  ...   \n",
       "\n",
       "   f1_score_session_13  f1_score_session_14  f1_score_session_15  \\\n",
       "0             0.903456             0.854116             0.820349   \n",
       "\n",
       "   f1_score_session_16  f1_score_session_17  f1_score_session_18  \\\n",
       "0              0.83538             0.933664             0.909538   \n",
       "\n",
       "   f1_score_session_19  f1_score_session_20  f1_score_session_21  \\\n",
       "0             0.836646             0.802508             0.868471   \n",
       "\n",
       "   average_f1_score  \n",
       "0          0.860156  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# # Assuming each session has a corresponding f1 score\n",
    "# data = {\n",
    "#     'batch_size': batch_size[0] if batch_size else None,\n",
    "#     'test_batch_size': test_batch_size[0] if test_batch_size else None,\n",
    "#     **{f'f1_score_session_{i+1}': float(score) for i, score in enumerate(f1_scores)}\n",
    "# }\n",
    "\n",
    "# # Calculating average F1 score\n",
    "# average_f1 = sum(map(float, f1_scores)) / len(f1_scores) if f1_scores else None\n",
    "# data['average_f1_score'] = average_f1\n",
    "\n",
    "# # Creating DataFrame\n",
    "# df = pd.DataFrame([data])\n",
    "\n",
    "# # Save to CSV\n",
    "# df.to_csv('results.csv', index=False)\n",
    "\n",
    "# # Display DataFrame\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.7553501556584393',\n",
       " '0.7909164539233584',\n",
       " '0.8450313548255183',\n",
       " '0.8956708233574734',\n",
       " '0.8794391358810065',\n",
       " '0.8753941441441441',\n",
       " '0.8095277675528694',\n",
       " '0.7697075548812402',\n",
       " '0.9186191293658866',\n",
       " '0.9255669518176288',\n",
       " '0.8975391651592204',\n",
       " '0.9363776084993994',\n",
       " '0.9034558304631297',\n",
       " '0.8541157538219718',\n",
       " '0.8203489231482184',\n",
       " '0.83537966546721',\n",
       " '0.9336638094254536',\n",
       " '0.909538041511112',\n",
       " '0.836645920633465',\n",
       " '0.8025078369905957',\n",
       " '0.8684714710776108']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
